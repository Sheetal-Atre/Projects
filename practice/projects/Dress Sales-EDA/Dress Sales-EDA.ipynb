{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading & Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>Decoration</th>\n",
       "      <th>Pattern Type</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>print</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>embroidary</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>bow</td>\n",
       "      <td>dot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6    M  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0    L  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0    L  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6    L  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5    M  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  Decoration Pattern Type  Recommendation  \n",
       "0            NaN    chiffon     ruffles       animal               1  \n",
       "1     microfiber        NaN     ruffles       animal               0  \n",
       "2       polyster        NaN         NaN        print               0  \n",
       "3           silk    chiffon  embroidary        print               1  \n",
       "4  chiffonfabric    chiffon         bow          dot               0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(\"Dress Sales.csv\")\n",
    "inp0.head()\n",
    "# inp1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have “Attribute DataSet” which contains a column named “Price”. Choose the correct statement from the following about its data type and variable type.\n",
    "- Integer type and numerical variable\n",
    "- Object type and categorical ordinal variable\n",
    "- Object type and categorical nominal variable\n",
    "- Float type and categorical variable.\n",
    "\n",
    "\n",
    "Following are the some of the types of variables:\n",
    "- **Numeric data type**: banking dataset: salary, balance, duration and age.\n",
    "- **Categorical data type**: banking dataset: education, job, marital, poutcome and month etc.\n",
    "- **Ordinal data type**: banking dataset: Age group.\n",
    "- **Time and date type** \n",
    "- **Coordinates type of data**: latitude and longitude type.\n",
    "\n",
    "\n",
    "There are two types of categorical variable, nominal and ordinal.\n",
    " - A nominal variable has no intrinsic ordering to its categories. For example, gender is a categorical variable having two categories (male and female) with no intrinsic ordering to the categories. \n",
    "In research activities a YES/NO scale is nominal. It has no order and there is no distance between YES and NO. There are also highly sophisticated modelling techniques available for nominal data. An ordinal scale is next up the list in terms of power of measurement.\n",
    "\n",
    " - An ordinal variable has a clear ordering.Price - (high,low,etc) is the categorical type with a specific order in it; hence, it is an ordinal type of data.\n",
    "As Price has some increasing order such as low, medium and high; hence, it is not nominal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n",
      "\n",
      "\n",
      " Price value counts\n",
      " Average      240\n",
      "Low          165\n",
      "Medium        30\n",
      "very-high     21\n",
      "High          21\n",
      "Name: Price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(\"Dress Sales.csv\")\n",
    "inp0.head()\n",
    "# inp1.head()\n",
    "inp0.info()\n",
    "print(\"\\n\\n Price value counts\\n\",inp0.Price.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another column in “Attribute DataSet” named as “Recommendation”, choose the correct statement about its data type and variable type.\n",
    "- Integer type and categorical\n",
    "\n",
    "Answer : \n",
    "It is an integer type and has categories in it like 1 and 0. You can check its type using the following code.\n",
    "inp0.info()\n",
    "\n",
    "- Object type and categorical\n",
    "- Integer type and continuous numerical\n",
    "- Object type only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Identifying var type === \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n",
      "\n",
      "\n",
      " Price value counts\n",
      " Average      240\n",
      "Low          165\n",
      "Medium        30\n",
      "very-high     21\n",
      "High          21\n",
      "Name: Price, dtype: int64\n",
      "\n",
      "\n",
      " Recommendation value counts\n",
      " 0    274\n",
      "1    205\n",
      "Name: Recommendation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(\"Dress Sales.csv\")\n",
    "inp0.head()\n",
    "# inp1.head()\n",
    "\n",
    "print(\"\\n\\nIdentifying var type === \\n\")\n",
    "inp0.info()\n",
    "print(\"\\n\\n Price value counts\\n\",inp0.Price.value_counts())\n",
    "print(\"\\n\\n Recommendation value counts\\n\",inp0.Recommendation.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following column do you think are of no use in “Attribute DataSet”.\n",
    "- Dress_ID\n",
    "- Price\n",
    "- Size and material\n",
    "- NeckLine\n",
    "- None of the above\n",
    "Answer : \n",
    "<br/> All the columns mentioned above in the dataset are equally important.\n",
    "\n",
    "#### Note : \n",
    "There are two datasets in this case study. The common information from both the datasets can only be fetched using dress ID; hence, this is a very important column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Identifying var type === \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n",
      "\n",
      "\n",
      " Price value counts\n",
      " Average      240\n",
      "Low          165\n",
      "Medium        30\n",
      "very-high     21\n",
      "High          21\n",
      "Name: Price, dtype: int64\n",
      "\n",
      "\n",
      " Recommendation value counts\n",
      " 0    274\n",
      "1    205\n",
      "Name: Recommendation, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  479 non-null    object \n",
      " 9   14-09-2013  479 non-null    object \n",
      " 10  16-09-2013  479 non-null    object \n",
      " 11  18-09-2013  479 non-null    object \n",
      " 12  20-09-2013  479 non-null    object \n",
      " 13  22-09-2013  479 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(\"Dress Sales.csv\")\n",
    "inp0.head()\n",
    "# inp1.head()\n",
    "\n",
    "print(\"\\n\\nIdentifying var type === \\n\")\n",
    "inp0.info()\n",
    "print(\"\\n\\n Price value counts\\n\",inp0.Price.value_counts())\n",
    "print(\"\\n\\n Recommendation value counts\\n\",inp0.Recommendation.value_counts())\n",
    "\n",
    "\n",
    "# Print the information about the attributes of inp0 and inp1.\n",
    "inp0.info()\n",
    "inp1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Rows and Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a column in “Attribute Dataset” named as ‘Size’. This column contains the values in abbreviation format. Write a code in Python to convert the followings:\n",
    "\n",
    "- M into  “Medium”\n",
    "- L into  “Large”\n",
    "- XL into “Extra large”\n",
    "- free into “Free”\n",
    "- S, s & small into “Small”.\n",
    "\n",
    "Now once you are done with changes in the dataset, what is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named “Size”?\n",
    "\n",
    "\n",
    "2.9%, 35.7%, 7.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>Decoration</th>\n",
       "      <th>Pattern Type</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>print</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>embroidary</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>bow</td>\n",
       "      <td>dot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>990559192</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.7</td>\n",
       "      <td>M</td>\n",
       "      <td>winter</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>halfsleeve</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>striped</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>713391965</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.7</td>\n",
       "      <td>M</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>solid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>532874347</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.7</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lace</td>\n",
       "      <td>solid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>655464934</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>winter</td>\n",
       "      <td>boat-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>silk</td>\n",
       "      <td>broadcloth</td>\n",
       "      <td>applique</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>919930954</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.4</td>\n",
       "      <td>free</td>\n",
       "      <td>Summer</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>cotton</td>\n",
       "      <td>Corduroy</td>\n",
       "      <td>lace</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dress_ID    Style    Price  Rating  Size  Season   NeckLine  \\\n",
       "0    1006032852     Sexy      Low     4.6     M  Summer     o-neck   \n",
       "1    1212192089   Casual      Low     0.0     L  Summer     o-neck   \n",
       "2    1190380701  vintage     High     0.0     L  Automn     o-neck   \n",
       "3     966005983    Brief  Average     4.6     L  Spring     o-neck   \n",
       "4     876339541     cute      Low     4.5     M  Summer     o-neck   \n",
       "..          ...      ...      ...     ...   ...     ...        ...   \n",
       "474   990559192    Brief  Average     4.7     M  winter     o-neck   \n",
       "475   713391965   Casual      Low     4.7     M  Spring     o-neck   \n",
       "476   532874347   Casual  Average     4.7     M  Summer     v-neck   \n",
       "477   655464934   Casual  Average     4.6     L  winter  boat-neck   \n",
       "478   919930954   Casual      Low     4.4  free  Summer     v-neck   \n",
       "\n",
       "    SleeveLength       Material  FabricType  Decoration Pattern Type  \\\n",
       "0      sleevless            NaN     chiffon     ruffles       animal   \n",
       "1          Petal     microfiber         NaN     ruffles       animal   \n",
       "2           full       polyster         NaN         NaN        print   \n",
       "3           full           silk     chiffon  embroidary        print   \n",
       "4      butterfly  chiffonfabric     chiffon         bow          dot   \n",
       "..           ...            ...         ...         ...          ...   \n",
       "474   halfsleeve        acrylic     chiffon         NaN      striped   \n",
       "475         full       polyster         NaN         NaN        solid   \n",
       "476         full         cotton         NaN        lace        solid   \n",
       "477    sleevless           silk  broadcloth    applique        print   \n",
       "478        short         cotton    Corduroy        lace        solid   \n",
       "\n",
       "     Recommendation  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "..              ...  \n",
       "474               0  \n",
       "475               1  \n",
       "476               1  \n",
       "477               1  \n",
       "478               0  \n",
       "\n",
       "[479 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Size Column fixing, correcting size abbreviation\n",
      "\n",
      "\n",
      "Printing col values and percentages\n",
      "M        35.699374\n",
      "free     34.446764\n",
      "L        19.415449\n",
      "S         7.098121\n",
      "XL        2.922756\n",
      "s         0.208768\n",
      "small     0.208768\n",
      "Name: Size, dtype: float64\n",
      "\n",
      "Printing col values and percentages\n",
      "Medium         35.699374\n",
      "Free           34.446764\n",
      "Large          19.415449\n",
      "Small           7.515658\n",
      "Extra large     2.922756\n",
      "Name: Size, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "display_data(inp0)\n",
    "\n",
    "#inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "value_percentage(inp0.Size)\n",
    "inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "value_percentage(inp0.Size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts of each category in \"Size\" column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute/Remove Missing values\n",
    "\n",
    "You are given another dataset named “Dress Sales”. Now if you observe the datatypes of the columns using ‘inp1.info()’ command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n",
    "\n",
    "Now, if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Choose the correct option with the reason for the error and also how to remove this error.\n",
    "\n",
    "The error occurred because there are some blank entries in such specific columns, and when you convert these null values into float, it shows the error message. To remove this error, you need to remove such null values from the dataset.\n",
    "\n",
    "Error occurred because there are string entries in such columns. You should replace these string values with null values and then convert it into float type.\n",
    "\n",
    "The error occurred because object type cannot be converted into float type. This error cannot be removed, and you have to deal with the object data types in such columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID        0\n",
       "29-08-2013      0\n",
       "31-08-2013      0\n",
       "09-02-2013      0\n",
       "09-04-2013      0\n",
       "09-06-2013      0\n",
       "09-08-2013      0\n",
       "09-10-2013      0\n",
       "09-12-2013      0\n",
       "14-09-2013      0\n",
       "16-09-2013      0\n",
       "18-09-2013      0\n",
       "20-09-2013      0\n",
       "22-09-2013      0\n",
       "24-09-2013      0\n",
       "26-09-2013    222\n",
       "28-09-2013      0\n",
       "30-09-2013    257\n",
       "10-02-2013    259\n",
       "10-04-2013    258\n",
       "10-06-2013      0\n",
       "10-08-2013    255\n",
       "10-10-2013    255\n",
       "10-12-2013      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given another dataset named “Dress Sales”. Now if you observe the datatypes of the columns using ‘inp1.info()’ command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n",
    "\n",
    "Now if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Try to correct this error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  479 non-null    object \n",
      " 9   14-09-2013  479 non-null    object \n",
      " 10  16-09-2013  479 non-null    object \n",
      " 11  18-09-2013  479 non-null    object \n",
      " 12  20-09-2013  479 non-null    object \n",
      " 13  22-09-2013  479 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp1.isnull().sum()\n",
    "\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "inp1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  479 non-null    object \n",
      " 9   14-09-2013  479 non-null    object \n",
      " 10  16-09-2013  479 non-null    object \n",
      " 11  18-09-2013  479 non-null    object \n",
      " 12  20-09-2013  479 non-null    object \n",
      " 13  22-09-2013  479 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Removed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-aaf000cf7c10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m#ValueError: could not convert string to float: 'Removed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0minp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"09-12-2013\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"09-12-2013\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sheetal.atre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5697\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5698\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5699\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheetal.atre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheetal.atre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheetal.atre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheetal.atre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    895\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Removed'"
     ]
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp1.isnull().sum()\n",
    "\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "inp1.info()\n",
    "\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  478 non-null    object \n",
      " 9   14-09-2013  478 non-null    object \n",
      " 10  16-09-2013  478 non-null    object \n",
      " 11  18-09-2013  478 non-null    object \n",
      " 12  20-09-2013  478 non-null    object \n",
      " 13  22-09-2013  478 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dress_ID        0\n",
       "29-08-2013      0\n",
       "31-08-2013      0\n",
       "09-02-2013      0\n",
       "09-04-2013      0\n",
       "09-06-2013      0\n",
       "09-08-2013      0\n",
       "09-10-2013      0\n",
       "09-12-2013      1\n",
       "14-09-2013      1\n",
       "16-09-2013      1\n",
       "18-09-2013      1\n",
       "20-09-2013      1\n",
       "22-09-2013      1\n",
       "24-09-2013      0\n",
       "26-09-2013    222\n",
       "28-09-2013      0\n",
       "30-09-2013    257\n",
       "10-02-2013    259\n",
       "10-04-2013    258\n",
       "10-06-2013      0\n",
       "10-08-2013    255\n",
       "10-10-2013    255\n",
       "10-12-2013      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "#inp1.isnull().sum()\n",
    "\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "#inp1.info()\n",
    "\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "convert_cols_to_float(inp1)\n",
    "inp1.info()\n",
    "\n",
    "# Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "inp1.isnull().sum()\n",
    "\n",
    "# inp1[\"09-12-2013\"].isnull().value_counts()\n",
    "# inp1[\"14-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"16-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"18-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"20-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"22-09-2013\"].isnull().value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the object type columns in \"Dress Sales\" into float type of data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see the null counts in “Dress Sales” dataset after performing all the operations that have been mentioned in jupyter notebook, you will find that there are some columns in “Dress Sales” data where there are more than 40% of missing values. Based on your understanding of dealing with missing values do the following steps.\n",
    "\n",
    "\n",
    "Handling Missing Values\n",
    "\n",
    "When you see the null counts in “Dress Sales” dataset after performing all the operations that have been mentioned in Jupyter notebook, you will find that there are some columns in “Dress Sales” data where the number of missing values is more than 40%. Based on your understanding of dealing with missing values, select the most appropriate statement, with the reason.\n",
    "\n",
    "\n",
    "These columns can be removed because they have a huge number of missing values. Moreover, if you see, the number of sales (numerical values) in such columns is not so high as compared to other Date columns. Hence, it is safe to remove such columns.\n",
    "Feedback :\n",
    "\n",
    "The huge number of missing values in such columns is one of the criteria, but another major criterion is that these dates have very small sales values and it is safe to remove them. You can refer to the following code to perform this operation:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.500000\n",
       "1      0.250000\n",
       "255    0.083333\n",
       "222    0.041667\n",
       "257    0.041667\n",
       "259    0.041667\n",
       "258    0.041667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "#inp1.isnull().sum()\n",
    "\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "#inp1.info()\n",
    "\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "convert_cols_to_float(inp1)\n",
    "#inp1.info()\n",
    "\n",
    "# Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "# inp1[\"09-12-2013\"].isnull().value_counts()\n",
    "# inp1[\"14-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"16-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"18-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"20-09-2013\"].isnull().value_counts()\n",
    "# inp1[\"22-09-2013\"].isnull().value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress_ID        0\n",
      "29-08-2013      0\n",
      "31-08-2013      0\n",
      "09-02-2013      0\n",
      "09-04-2013      0\n",
      "09-06-2013      0\n",
      "09-08-2013      0\n",
      "09-10-2013      0\n",
      "09-12-2013      1\n",
      "14-09-2013      1\n",
      "16-09-2013      1\n",
      "18-09-2013      1\n",
      "20-09-2013      1\n",
      "22-09-2013      1\n",
      "24-09-2013      0\n",
      "26-09-2013    222\n",
      "28-09-2013      0\n",
      "30-09-2013    257\n",
      "10-02-2013    259\n",
      "10-04-2013    258\n",
      "10-06-2013      0\n",
      "10-08-2013    255\n",
      "10-10-2013    255\n",
      "10-12-2013      0\n",
      "dtype: int64\n",
      "Dress_ID      0\n",
      "29-08-2013    0\n",
      "31-08-2013    0\n",
      "09-02-2013    0\n",
      "09-04-2013    0\n",
      "09-06-2013    0\n",
      "09-08-2013    0\n",
      "09-10-2013    0\n",
      "09-12-2013    1\n",
      "14-09-2013    1\n",
      "16-09-2013    1\n",
      "18-09-2013    1\n",
      "20-09-2013    1\n",
      "22-09-2013    1\n",
      "24-09-2013    0\n",
      "28-09-2013    0\n",
      "10-06-2013    0\n",
      "10-12-2013    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "#inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "print(inp1.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should categorise the dates into seasons in “Dress Sales” data to simplify the analysis according to the following criteria:\n",
    "- June, July and August: Summer.\n",
    "- September, October and November: Autumn.\n",
    "- December, January and February: WInter.\n",
    "- March, April and May: Spring.\n",
    "\n",
    "\n",
    "Which of the seasons has the lowest sales among all the seasons, and what is its value?\n",
    "Spring, 135343\n",
    "\n",
    "Spring, 143600\n",
    "Feedback :\n",
    "\n",
    "Write the code to club the dates into seasons according to the criteria and then find the sum of each season in “Dress Sales”. You can refer to the following code to perform such an operation:\n",
    "\n",
    "inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "\n",
    "inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "\n",
    "inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "\n",
    "inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "Correct\n",
    "\n",
    "Autumn, 135343\n",
    "\n",
    "Autumn, 143600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  478 non-null    object \n",
      " 9   14-09-2013  478 non-null    object \n",
      " 10  16-09-2013  478 non-null    object \n",
      " 11  18-09-2013  478 non-null    object \n",
      " 12  20-09-2013  478 non-null    object \n",
      " 13  22-09-2013  478 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  28-09-2013  479 non-null    int64  \n",
      " 16  10-06-2013  479 non-null    int64  \n",
      " 17  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(1), int64(11), object(6)\n",
      "memory usage: 67.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  478 non-null    object \n",
      " 9   14-09-2013  478 non-null    object \n",
      " 10  16-09-2013  478 non-null    object \n",
      " 11  18-09-2013  478 non-null    object \n",
      " 12  20-09-2013  478 non-null    object \n",
      " 13  22-09-2013  478 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  28-09-2013  479 non-null    int64  \n",
      " 16  10-06-2013  479 non-null    int64  \n",
      " 17  10-12-2013  479 non-null    int64  \n",
      " 18  Summer      479 non-null    int64  \n",
      " 19  Winter      479 non-null    int64  \n",
      " 20  Autumn      479 non-null    int64  \n",
      " 21  Spring      479 non-null    int64  \n",
      "dtypes: float64(1), int64(15), object(6)\n",
      "memory usage: 82.5+ KB\n",
      "Summer :  691907\n",
      "Winter :  314990\n",
      "Autumn :  518580\n",
      "Spring :  143600\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "\n",
    "    inp1.info()\n",
    "\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "\n",
    "    inp1.info()\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria and then find the sum of each season in “Dress Sales”. You can refer to the following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "print(\"Summer : \",inp1.Summer.sum())\n",
    "print(\"Winter : \", inp1.Winter.sum())\n",
    "print(\"Autumn : \",inp1.Autumn.sum())\n",
    "print(\"Spring : \",inp1.Spring.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of sales in each seasons in inp1 i.e. \"Dress Sales\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge inp1 with inp0 with left join manner, so that the information of inp0 should remain intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>...</th>\n",
       "      <th>20-09-2013</th>\n",
       "      <th>22-09-2013</th>\n",
       "      <th>24-09-2013</th>\n",
       "      <th>28-09-2013</th>\n",
       "      <th>10-06-2013</th>\n",
       "      <th>10-12-2013</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Autumn</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>3386</td>\n",
       "      <td>3479</td>\n",
       "      <td>3554</td>\n",
       "      <td>3706</td>\n",
       "      <td>3897</td>\n",
       "      <td>4048</td>\n",
       "      <td>13899</td>\n",
       "      <td>6539</td>\n",
       "      <td>10190</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2106</td>\n",
       "      <td>2454</td>\n",
       "      <td>2710</td>\n",
       "      <td>3258</td>\n",
       "      <td>3911</td>\n",
       "      <td>4277</td>\n",
       "      <td>6216</td>\n",
       "      <td>4847</td>\n",
       "      <td>7132</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1812</td>\n",
       "      <td>1845</td>\n",
       "      <td>1878</td>\n",
       "      <td>1914</td>\n",
       "      <td>1952</td>\n",
       "      <td>1963</td>\n",
       "      <td>7213</td>\n",
       "      <td>3289</td>\n",
       "      <td>5429</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1824</td>\n",
       "      <td>1919</td>\n",
       "      <td>2032</td>\n",
       "      <td>2252</td>\n",
       "      <td>2544</td>\n",
       "      <td>2736</td>\n",
       "      <td>7706</td>\n",
       "      <td>4040</td>\n",
       "      <td>5854</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6    M  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0    L  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0    L  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6    L  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5    M  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  ... 20-09-2013 22-09-2013  24-09-2013  \\\n",
       "0            NaN    chiffon  ...       3386       3479        3554   \n",
       "1     microfiber        NaN  ...       2106       2454        2710   \n",
       "2       polyster        NaN  ...         10         11          11   \n",
       "3           silk    chiffon  ...       1812       1845        1878   \n",
       "4  chiffonfabric    chiffon  ...       1824       1919        2032   \n",
       "\n",
       "   28-09-2013  10-06-2013  10-12-2013  Summer  Winter  Autumn  Spring  \n",
       "0        3706        3897        4048   13899    6539   10190    2660  \n",
       "1        3258        3911        4277    6216    4847    7132     750  \n",
       "2          11          11          11      40      18      31       7  \n",
       "3        1914        1952        1963    7213    3289    5429    1455  \n",
       "4        2252        2544        2736    7706    4040    5854    1396  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "# Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "inp0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               2\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              2\n",
       "NeckLine            3\n",
       "SleeveLength        2\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "Summer              0\n",
       "Winter              0\n",
       "Autumn              0\n",
       "Spring              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "# Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "inp0.head()\n",
    "\n",
    "# Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "inp0.drop(inp0.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the null count of inp0 to get the idea about the missing values in data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "# Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "inp0.head()\n",
    "\n",
    "# Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "inp0.drop(inp0.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "\n",
    "# Print the null count of each columns in inp0 dataframe i.e. \n",
    "# combined data frame of inp0 and inp1 without date columns.\n",
    "inp0.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are two types of variables one with a large number of missing values and another is very less number of missing values. These two columns can be categorized as:\n",
    "\n",
    "Type-1: Missing values are very less (around 2 or 3 missing values): Price, Season, NeckLine, SleeveLength, Winter and Autumn. \n",
    "\n",
    "Type-2: Missing values are large in numbers (more than 15%): Material, FabricType, Decoration and Pattern Type.\n",
    "\n",
    "\n",
    "\n",
    "You should create a separate category named as Missing category in Type-2 columns\n",
    "and just drop the missing values of Type-1 columns.\n",
    "Feedback :\n",
    "\n",
    "This is the best way to deal with missing values. You can refer to the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "def combine_datasets(inp0,inp1):    \n",
    "    # Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "    inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "    inp0.head()\n",
    "    return inp0\n",
    "\n",
    "def drop_date_cols(inp1):    \n",
    "    # Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "    inp1.drop(inp1.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "\n",
    "    \n",
    "def drop_missing_type1_rows(inp0):\n",
    "    # Drop the missing values of Type-1 columns:\n",
    "    inp0 = inp0[~inp0.Price.isnull()]\n",
    "    inp0 = inp0[~inp0.Season.isnull()]\n",
    "    inp0 = inp0[~inp0.NeckLine.isnull()]\n",
    "    inp0 = inp0[~inp0.SleeveLength.isnull()]\n",
    "    inp0 = inp0[~inp0.Winter.isnull()]\n",
    "    inp0 = inp0[~inp0.Autumn.isnull()]\n",
    "    return inp0\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "drop_date_cols(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "\n",
    "inp0 = combine_datasets(inp0,inp1)\n",
    "print(inp0.shape)\n",
    "\n",
    "\n",
    "# Print the null count of each columns in inp0 dataframe i.e. \n",
    "# combined data frame of inp0 and inp1 without date columns.\n",
    "inp0.isnull().sum()\n",
    "\n",
    "# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "inp0 = drop_missing_type1_rows(inp0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "def combine_datasets(inp0,inp1):    \n",
    "    # Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "    inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "    inp0.head()\n",
    "    return inp0\n",
    "\n",
    "def drop_date_cols(inp1):    \n",
    "    # Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "    inp1.drop(inp1.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "\n",
    "    \n",
    "def drop_missing_type1_rows(inp0):\n",
    "    # Drop the missing values of Type-1 columns:\n",
    "    inp0 = inp0[~inp0.Price.isnull()]\n",
    "    inp0 = inp0[~inp0.Season.isnull()]\n",
    "    inp0 = inp0[~inp0.NeckLine.isnull()]\n",
    "    inp0 = inp0[~inp0.SleeveLength.isnull()]\n",
    "    inp0 = inp0[~inp0.Winter.isnull()]\n",
    "    inp0 = inp0[~inp0.Autumn.isnull()]\n",
    "    return inp0\n",
    "\n",
    "def new_categvals_null_to_Missing(inp0):\n",
    "    # Create a separate category ‘Missing’ in Type-2 column:\n",
    "\n",
    "    inp0.Material= inp0.Material.replace(np.nan, \"Missing\")\n",
    "\n",
    "    inp0.FabricType= inp0.FabricType.replace(np.nan, \"Missing\")\n",
    "\n",
    "    inp0.Decoration= inp0.Decoration.replace(np.nan, \"Missing\")\n",
    "    inp0['Pattern Type']= inp0['Pattern Type'].replace(np.nan, \"Missing\")\n",
    "    return inp0\n",
    "\n",
    "    \n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "drop_date_cols(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "\n",
    "inp0 = combine_datasets(inp0,inp1)\n",
    "print(inp0.shape)\n",
    "\n",
    "\n",
    "# Print the null count of each columns in inp0 dataframe i.e. \n",
    "# combined data frame of inp0 and inp1 without date columns.\n",
    "inp0.isnull().sum()\n",
    "\n",
    "# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "inp0 = drop_missing_type1_rows(inp0)\n",
    "\n",
    "# Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\n",
    "inp0 = new_categvals_null_to_Missing(inp0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given dataset, there are certain discrepancies with the categorical names such as irregular spellings. Choose the correct option of columns with irregular categories and update them.\n",
    " \n",
    "- Season, NeckLine\n",
    "- Price, Material\n",
    "- fabricType, Decoration\n",
    "- Season, SleeveLength\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Season, SleeveLength\n",
    "Feedback :\n",
    "\n",
    "Season and sleeve length contain some spelling mistakes in the categorical names,\n",
    "which need to be rectified. You can refer to the following code to perform this operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def read_data(filename):\n",
    "    #Read the data in pandas\n",
    "    inp0= pd.read_csv(filename)    \n",
    "    return inp0\n",
    "\n",
    "def display_data(df):\n",
    "    display(df)\n",
    "\n",
    "def identify_var_types(col):\n",
    "    print(\"\\n\\nPrinting attributes information\\n\")\n",
    "    inp0.info()\n",
    "    \n",
    "    print(\"\\n\\nPrinting col value counts\\n\")\n",
    "    print(col.value_counts())\n",
    "\n",
    "def value_percentage(col):\n",
    "    print(\"\\nPrinting col values and percentages\")\n",
    "    print(100 * col.value_counts(normalize=True))\n",
    "\n",
    "def size_abbreviations(val):\n",
    "    if val == 'M' : \n",
    "        return \"Medium\"\n",
    "    elif val == 'L' : \n",
    "        return   \"Large\"\n",
    "    elif val == 'XL':\n",
    "        return \"Extra large\"\n",
    "    elif val == 'free':\n",
    "        return \"Free\"\n",
    "    elif np.logical_or(np.logical_or(val == 'S',val == 's'), val == 'small') :\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    OR\n",
    "    \n",
    "#     inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "#     inp0.Size= inp0.Size.replace('XL', \"Extra large\")\n",
    "\n",
    "\n",
    "def convert_cols_to_float(inp1):\n",
    "#     inp1[\"09-12-2013\"] = inp1[\"09-12-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"14-09-2013\"] = inp1[\"14-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"16-09-2013\"] = inp1[\"16-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"18-09-2013\"] = inp1[\"18-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"20-09-2013\"] = inp1[\"20-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#     inp1[\"22-09-2013\"] = inp1[\"22-09-2013\"].apply(lambda x: float(x) if isinstance(x, (int, float)) else np.NaN)\n",
    "#OR\n",
    "# Error occurred because there are string entries in such columns. \n",
    "# You should replace these string values with null values and then convert it into float type.\n",
    "# Feedback :\n",
    "\n",
    "# Because there is one string value in each of these columns, it is showing the error. \n",
    "# You cannot convert a string into float type, and once you replace string with a null value, \n",
    "# you will be able to convert it into float type.\n",
    "\n",
    "# You can convert the string values into null using the following codes:\n",
    "    inp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "    inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN\n",
    "    return inp1\n",
    "\n",
    "def correct_cols_drop_blank_cols(inp1):\n",
    "    \n",
    "\n",
    "    # Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "    inp1.isnull().sum().value_counts(normalize=True)\n",
    "\n",
    "    # Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "    #inp1 = inp1.dropna(thresh=inp1.shape[0]*0.4,how='all',axis=1)\n",
    "\n",
    "    #OR\n",
    "    inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "    inp1= inp1.drop([\"10-10-2013\"] , axis= 1)\n",
    "    return inp1\n",
    "\n",
    "def seasonwise_sale(inp1):\n",
    "    # Create the four seasons columns in inp1, according to the above criteria.\n",
    "    # June, July and August - 8: Summer.\n",
    "    # - September, October and November - 11: Autumn.\n",
    "    # - December, January and February - 2: WInter.\n",
    "    # - March, April and May - 5: Spring.\n",
    "    summer_col = inp1.loc[: , [\"29-08-2013\",\"31-08-2013\",\"09-08-2013\",\n",
    "                               \"09-06-2013\",\"10-06-2013\"]]\n",
    "    inp1['Summer'] = summer_col.sum(axis=1)\n",
    "\n",
    "    winter_col = inp1.loc[: , [\"09-02-2013\",\"09-12-2013\",\"10-12-2013\"]]\n",
    "    inp1['Winter'] = winter_col.sum(axis=1)\n",
    "\n",
    "    autumn_col = inp1.loc[: , [\"09-10-2013\",\"14-09-2013\",\"16-09-2013\",\"18-09-2013\",\n",
    "                               \"20-09-2013\",\"22-09-2013\",\"24-09-2013\",\"28-09-2013\"]]\n",
    "    inp1['Autumn'] = autumn_col.sum(axis=1)\n",
    "\n",
    "    spring_col = inp1.loc[: , [\"09-04-2013\"]]\n",
    "    inp1['Spring'] = spring_col.sum(axis=1)\n",
    "\n",
    "    return inp1\n",
    "\n",
    "    # OR\n",
    "    #Correct\n",
    "    # Spring, 143600\n",
    "    # # Feedback :\n",
    "\n",
    "    # # Write the code to club the dates into seasons according to the criteria\n",
    "#     and then find the sum of each season in “Dress Sales”. You can refer to the \n",
    "#     following code to perform such an operation:\n",
    "\n",
    "#     inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "#     inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "#     inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "#     inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)\n",
    "\n",
    "#     return inp1\n",
    "\n",
    "def combine_datasets(inp0,inp1):    \n",
    "    # Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "    inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "    inp0.head()\n",
    "    return inp0\n",
    "\n",
    "def drop_date_cols(inp1):    \n",
    "    # Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "    inp1.drop(inp1.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "\n",
    "    \n",
    "def drop_missing_type1_rows(inp0):\n",
    "    # Drop the missing values of Type-1 columns:\n",
    "    inp0 = inp0[~inp0.Price.isnull()]\n",
    "    inp0 = inp0[~inp0.Season.isnull()]\n",
    "    inp0 = inp0[~inp0.NeckLine.isnull()]\n",
    "    inp0 = inp0[~inp0.SleeveLength.isnull()]\n",
    "    inp0 = inp0[~inp0.Winter.isnull()]\n",
    "    inp0 = inp0[~inp0.Autumn.isnull()]\n",
    "    return inp0\n",
    "\n",
    "def newcateg_replace_null_with_Missing(inp0):\n",
    "    # Create a separate category ‘Missing’ in Type-2 column:\n",
    "\n",
    "    inp0.Material= inp0.Material.replace(np.nan, \"Missing\")\n",
    "\n",
    "    inp0.FabricType= inp0.FabricType.replace(np.nan, \"Missing\")\n",
    "\n",
    "    inp0.Decoration= inp0.Decoration.replace(np.nan, \"Missing\")\n",
    "    inp0['Pattern Type']= inp0['Pattern Type'].replace(np.nan, \"Missing\")\n",
    "    return inp0\n",
    "\n",
    "def check_cols_reqd_for_correction(inp0):\n",
    "    #all the options have Price col which does not need correction\n",
    "    # - Season, NeckLine, Price\n",
    "    # - Price, Material,Rating\n",
    "    # - fabricType, Decoration, Price\n",
    "    # - Season, SleeveLength\n",
    "    inp0.Season.value_counts()\n",
    "    # inp0.NeckLine.value_counts()\n",
    "    # inp0.Price.value_counts() #-- not needed\n",
    "    # inp0.Material.value_counts() #-- not needed\n",
    "    # inp0.FabricType.value_counts()\n",
    "    # inp0.Rating.value_counts()\n",
    "    # inp0.Decoration.value_counts()#-- not needed\n",
    "    inp0.SleeveLength.value_counts()\n",
    "\n",
    "def correct_spellings_type2(inp0):\n",
    "    \n",
    "    #correcting the season spellings.\n",
    "\n",
    "    inp0.Season= inp0.Season.replace('Automn', \"Autumn\")\n",
    "\n",
    "    inp0.Season= inp0.Season.replace('spring', \"Spring\")\n",
    "\n",
    "    inp0.Season= inp0.Season.replace('winter', \"Winter\")\n",
    "\n",
    "\n",
    "\n",
    "    #correcting the SleeveLength.\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace(['cap-sleeves', 'capsleeves'], \"cap sleeves\")\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace('full', \"full sleeves\")\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace(['half','halfsleeve'], \"half sleeves\")\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace(['sleevless', 'sleeevless', 'sleeveless', 'sleveless'], \"sleeve less\")\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace(['threequarter','threequater', 'thressqatar'], \"three quater\")\n",
    "\n",
    "    inp0.SleeveLength= inp0.SleeveLength.replace(['turndowncollor','urndowncollor'], \"turn down collar\")\n",
    "\n",
    "inp0 = read_data(\"Attribute DataSet.csv\")\n",
    "#display_data(inp0)\n",
    "\n",
    "inp1 = read_data(\"Dress Sales.csv\")\n",
    "#display_data(inp1)\n",
    "\n",
    "# print(\"\\n\\nIdentifying var types === \\n\")\n",
    "# identify_var_types(inp0.Price)\n",
    "# identify_var_types(inp0.Recommendation)\n",
    "# value_percentage(inp0.Recommendation)\n",
    "\n",
    "# print(\"\\n\\n Size Column fixing, correcting size abbreviation\\n\")\n",
    "# value_percentage(inp0.Size)\n",
    "# inp0.Size = inp0.Size.apply(size_abbreviations)\n",
    "# value_percentage(inp0.Size)\n",
    "\n",
    "\n",
    "# Print the null count of each variables of inp0 and inp1.\n",
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "#ValueError: could not convert string to float: 'Removed'\n",
    "# inp1.info()\n",
    "inp1 = convert_cols_to_float(inp1)\n",
    "\n",
    "# print(inp1.isnull().sum())\n",
    "inp1 = correct_cols_drop_blank_cols(inp1)\n",
    "# print(inp1.isnull().sum())\n",
    "\n",
    "# inp1.info()\n",
    "inp1 = seasonwise_sale(inp1)\n",
    "drop_date_cols(inp1)\n",
    "# inp1.info()\n",
    "# print(\"Summer : \",inp1.Summer.sum())\n",
    "# print(\"Winter : \", inp1.Winter.sum())\n",
    "# print(\"Autumn : \",inp1.Autumn.sum())\n",
    "# print(\"Spring : \",inp1.Spring.sum())\n",
    "\n",
    "\n",
    "inp0 = combine_datasets(inp0,inp1)\n",
    "print(inp0.shape)\n",
    "\n",
    "\n",
    "# Print the null count of each columns in inp0 dataframe i.e. \n",
    "# combined data frame of inp0 and inp1 without date columns.\n",
    "inp0.isnull().sum()\n",
    "\n",
    "# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "inp0 = drop_missing_type1_rows(inp0)\n",
    "\n",
    "# Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\n",
    "inp0 = newcateg_replace_null_with_Missing(inp0)\n",
    "\n",
    "#correcting the spellings.\n",
    "check_cols_reqd_for_correction(inp0)\n",
    "inp0 = correct_spellings_type2(inp0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the Spellings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Unordered Univariate Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named ‘Style’ in ‘Attribute Dataset’ which consists of the different style categories of the women apparels. Certain categories whose total sale is less than 50000 across all the seasons is considered under one single category as ‘Others’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following categories in ‘Style’ column can be grouped into ‘Others’ category? and perform the grouping operation in the notebook for further analysis.\n",
    "- Flare, fashion\n",
    "- Novelty, bohemian\n",
    "- OL, fashion, work\n",
    "- Novelty, fashion, Flare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Style\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of “cute” and “Others” category in “Style” column in “Attribute DataSet” respectively?\n",
    "- 46%, 5%\n",
    "- 9%, 2.1%\n",
    "- 2.1%, 5%\n",
    "- 13.8%, 9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each categories in the \"Style\" variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly Club Neckline, SLeeve length categories into \"Others\" which have less than 50000 sales across all the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Sleeve length\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club material, fabrictype, patterntype and decoration categories into \"Others\" which have less than 25000 sales across all the seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"material\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"fabric type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"patern type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"decoration\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caregorical Ordered Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an unordered variable in “Attribute DataSet”.\n",
    "- Style\n",
    "- Price\n",
    "- Season\n",
    "- Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable Univariate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the approximate difference between the maximum value and 75th percentile in “Autumn” column.\n",
    "- Approx 54000\n",
    "- Approx 55000\n",
    "- Approx 52000\n",
    "- Approx 50000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the numerical variale: \"Autumn\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot of \"Autumn\" column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest difference between the maximum value and 99th quantile of sales?\n",
    "- Winter\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Winter season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Summer season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Spring season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Autumn season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical- Categorical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following “Price” category has the lowest average value of rating?\n",
    "- very-high\n",
    "- Medium\n",
    "- Low\n",
    "- High\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Mean of Ratings for each Price category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median of the rating of “vintage” category in Style column?\n",
    "- 4.6\n",
    "- 4.7\n",
    "- 4.55\n",
    "- 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the median of Ratings for each Style category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest average value of sale for “Recommendation” value equals to 1.\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn\n",
    "- Winter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spring sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autumn sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winter sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical categorical bivariate analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following size categories has the highest positive recommendations?\n",
    "- Medium and extra large\n",
    "- Extra large and small\n",
    "- Free and small\n",
    "- Free and medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following pair of “Style” and “Price” category has the highest average of positive recommendations?\n",
    "- Price: medium and style: vintage\n",
    "- Price: medium and style: cute\n",
    "- Price: very high and style: party\n",
    "- Price: low and style: sexy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Style, price and Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following material type has no recommendation in summer and winter seasons?\n",
    "- Mix and Milksilk\n",
    "- Nylon and Rayon\n",
    "- Microfiber and Silk\n",
    "- Milksilk and Microfiber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Season, material and Recommendation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
